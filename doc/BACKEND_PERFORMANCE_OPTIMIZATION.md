# åç«¯æ€§èƒ½ä¼˜åŒ–ä¿®æ”¹æ–‡æ¡£

> **æ–‡æ¡£ç‰ˆæœ¬**: v1.0
> **åˆ›å»ºæ—¥æœŸ**: 2025-11-24
> **é€‚ç”¨é¡¹ç›®**: è¯„è®ºå®¡æ ¸å¹³å°ï¼ˆComment Review Platformï¼‰
> **ç›®æ ‡è¯»è€…**: åç«¯å¼€å‘è€…ã€AIç¼–ç¨‹è¾…åŠ©ç”¨æˆ·

---

## ğŸ“‹ ç›®å½•

1. [æ‰§è¡Œæ‘˜è¦](#æ‰§è¡Œæ‘˜è¦)
2. [æ€§èƒ½å®¡æŸ¥æ–¹æ³•è®º](#æ€§èƒ½å®¡æŸ¥æ–¹æ³•è®º)
3. [å‘ç°çš„æ€§èƒ½é—®é¢˜](#å‘ç°çš„æ€§èƒ½é—®é¢˜)
4. [ä¼˜åŒ–æ–¹æ¡ˆè¯¦è§£](#ä¼˜åŒ–æ–¹æ¡ˆè¯¦è§£)
5. [å®æ–½ä¼˜å…ˆçº§](#å®æ–½ä¼˜å…ˆçº§)
6. [é¢„æœŸæ€§èƒ½æå‡](#é¢„æœŸæ€§èƒ½æå‡)
7. [é£é™©è¯„ä¼°](#é£é™©è¯„ä¼°)
8. [æµ‹è¯•éªŒè¯è®¡åˆ’](#æµ‹è¯•éªŒè¯è®¡åˆ’)

---

## ğŸ¯ æ‰§è¡Œæ‘˜è¦

### å®¡æŸ¥ç»“è®º
é€šè¿‡å¯¹è¯„è®ºå®¡æ ¸å¹³å°åç«¯ä»£ç çš„æ·±åº¦åˆ†æï¼Œ**å‘ç°äº†7ä¸ªå…³é”®æ€§èƒ½ç“¶é¢ˆ**ï¼Œè¿™äº›é—®é¢˜åœ¨å½“å‰5000+ä»»åŠ¡è§„æ¨¡ä¸‹è™½æœªæ˜¾ç°ä¸¥é‡å½±å“ï¼Œä½†éšç€æ•°æ®é‡å¢é•¿ï¼ˆé¢„ä¼°10ä¸‡+ä»»åŠ¡æ—¶ï¼‰ï¼Œå°†å¯¼è‡´ï¼š
- **ç»Ÿè®¡APIå“åº”æ—¶é—´ä»< 1så¢é•¿åˆ°10s+**
- **æœç´¢åŠŸèƒ½ä»< 500mså¢é•¿åˆ°5s+**
- **æ•°æ®åº“è¿æ¥æ± è€—å°½é£é™©**
- **å†…å­˜å ç”¨å¢é•¿10å€+**

### å…³é”®æŒ‡æ ‡
| é—®é¢˜ç±»å‹ | ä¸¥é‡ç¨‹åº¦ | å½±å“èŒƒå›´ | ä¼˜åŒ–æ”¶ç›Š |
|---------|---------|---------|---------|
| ç»Ÿè®¡æŸ¥è¯¢Næ¬¡æ•°æ®åº“å¾€è¿” | ğŸ”´ é«˜ | ç®¡ç†å‘˜åå° | **å“åº”æ—¶é—´å‡å°‘80%** |
| æœç´¢å†…å­˜æ’åº | ğŸ”´ é«˜ | ä»»åŠ¡æœç´¢åŠŸèƒ½ | **å†…å­˜å ç”¨å‡å°‘90%** |
| è§†é¢‘URLé¢‘ç¹æŸ¥åº“ | ğŸŸ¡ ä¸­ | è§†é¢‘å®¡æ ¸ | **æ•°æ®åº“è´Ÿè½½å‡å°‘60%** |
| ç¼ºå°‘Redisç¼“å­˜ | ğŸŸ¡ ä¸­ | æ‰€æœ‰è¯»æ“ä½œ | **å“åº”æ—¶é—´å‡å°‘50%** |
| UNION ALLæŸ¥è¯¢è¿‡å¤š | ğŸŸ¡ ä¸­ | ç»Ÿè®¡åŠŸèƒ½ | **æŸ¥è¯¢æ—¶é—´å‡å°‘40%** |

---

## ğŸ” æ€§èƒ½å®¡æŸ¥æ–¹æ³•è®º

### å®¡æŸ¥èŒƒå›´
```
å®¡æŸ¥ä»£ç æ–‡ä»¶ï¼š
â”œâ”€â”€ internal/repository/stats_repo.go      (805è¡Œ - ç»Ÿè®¡ä»“åº“)
â”œâ”€â”€ internal/services/task_service.go      (353è¡Œ - ä»»åŠ¡æœåŠ¡)
â”œâ”€â”€ internal/services/video_service.go     (425è¡Œ - è§†é¢‘æœåŠ¡)
â”œâ”€â”€ internal/handlers/admin.go             (522è¡Œ - ç®¡ç†å‘˜æ¥å£)
â””â”€â”€ pkg/database/postgres.go               (æ•°æ®åº“è¿æ¥æ± é…ç½®)
```

### å®¡æŸ¥ç»´åº¦
1. **æ•°æ®åº“æŸ¥è¯¢æ•ˆç‡**: SQLå¤æ‚åº¦ã€ç´¢å¼•ä½¿ç”¨ã€N+1æŸ¥è¯¢
2. **å†…å­˜ä½¿ç”¨**: æ•°æ®åŠ è½½é‡ã€æ’åºåˆ†é¡µæ–¹å¼
3. **ç¼“å­˜ç­–ç•¥**: Redisä½¿ç”¨æƒ…å†µã€ç¼“å­˜å‘½ä¸­ç‡
4. **å¹¶å‘å¤„ç†**: è¿æ¥æ± é…ç½®ã€é”ç«äº‰
5. **APIè®¾è®¡**: æ‰¹é‡æ“ä½œã€åˆ†é¡µå®ç°

### æµ‹è¯•æ•°æ®å‡è®¾
- å½“å‰æ•°æ®é‡: 5,000 ä»»åŠ¡
- é¢„æœŸå¢é•¿: 100,000 ä»»åŠ¡ï¼ˆ6ä¸ªæœˆåï¼‰
- å¹¶å‘ç”¨æˆ·: å½“å‰10äºº â†’ é¢„æœŸ50äºº
- å®¡æ ¸å‘˜: 20äºº
- æ¯æ—¥æ–°å¢ä»»åŠ¡: 1,000æ¡

---

## ğŸš¨ å‘ç°çš„æ€§èƒ½é—®é¢˜

### é—®é¢˜1: ç»Ÿè®¡æŸ¥è¯¢æ‰§è¡Œå¤šæ¬¡æ•°æ®åº“å¾€è¿” ğŸ”´ ä¸¥é‡

**ä½ç½®**: `internal/repository/stats_repo.go:19-233`

**é—®é¢˜æè¿°**:
`GetOverviewStats()` å‡½æ•°ä¸ºäº†è·å–å®Œæ•´çš„ç»Ÿè®¡æ•°æ®ï¼Œæ‰§è¡Œäº†**10æ¬¡ç‹¬ç«‹çš„SQLæŸ¥è¯¢**ï¼š

```go
// ä¼ªä»£ç å±•ç¤ºé—®é¢˜
func (r *StatsRepository) GetOverviewStats() (*models.StatsOverview, error) {
    // æŸ¥è¯¢1: è¯„è®ºä¸€å®¡ä»»åŠ¡ç»Ÿè®¡
    r.db.QueryRow(commentFirstQuery).Scan(...)

    // æŸ¥è¯¢2: è¯„è®ºä¸€å®¡å®¡æ ¸ç»“æœç»Ÿè®¡
    r.db.QueryRow(commentFirstApprovalQuery).Scan(...)

    // æŸ¥è¯¢3: è¯„è®ºäºŒå®¡ä»»åŠ¡ç»Ÿè®¡
    r.db.QueryRow(commentSecondQuery).Scan(...)

    // æŸ¥è¯¢4: è¯„è®ºäºŒå®¡å®¡æ ¸ç»“æœç»Ÿè®¡
    r.db.QueryRow(commentSecondApprovalQuery).Scan(...)

    // æŸ¥è¯¢5: è§†é¢‘ä¸€å®¡ä»»åŠ¡ç»Ÿè®¡
    r.db.QueryRow(videoFirstQuery).Scan(...)

    // æŸ¥è¯¢6: è§†é¢‘ä¸€å®¡å®¡æ ¸ç»“æœç»Ÿè®¡
    r.db.QueryRow(videoFirstApprovalQuery).Scan(...)

    // æŸ¥è¯¢7: è§†é¢‘äºŒå®¡ä»»åŠ¡ç»Ÿè®¡
    r.db.QueryRow(videoSecondQuery).Scan(...)

    // æŸ¥è¯¢8: è§†é¢‘äºŒå®¡å®¡æ ¸ç»“æœç»Ÿè®¡
    r.db.QueryRow(videoSecondApprovalQuery).Scan(...)

    // æŸ¥è¯¢9: å®¡æ ¸å‘˜æ€»æ•°
    r.db.QueryRow(`SELECT COUNT(*) FROM users...`).Scan(...)

    // æŸ¥è¯¢10: æ´»è·ƒå®¡æ ¸å‘˜ï¼ˆ5ä¸ªUNIONæŸ¥è¯¢ï¼‰
    r.db.QueryRow(activeReviewersQuery).Scan(...)

    // æŸ¥è¯¢11-12: é˜Ÿåˆ—ç»Ÿè®¡å’Œè´¨é‡æŒ‡æ ‡
    getQueueStats()  // å†…éƒ¨åˆæœ‰å¤æ‚æŸ¥è¯¢
    getQualityMetrics()

    return stats, nil
}
```

**æ€§èƒ½å½±å“**:
- æ¯æ¬¡è¯·æ±‚éœ€è¦**10+ æ¬¡æ•°æ®åº“å¾€è¿”**
- ç½‘ç»œå»¶è¿Ÿç´¯ç§¯: `10 * 5ms = 50ms`ï¼ˆç†æƒ³æƒ…å†µï¼‰
- æ•°æ®åº“è´Ÿè½½é«˜: æ¯ä¸ªæŸ¥è¯¢éƒ½éœ€è¦æ‰«æè¡¨
- æ— æ³•åˆ©ç”¨æŸ¥è¯¢è®¡åˆ’ä¼˜åŒ–

**æ ¹æœ¬åŸå› **:
1. âŒ æœªä½¿ç”¨JOINåˆå¹¶æŸ¥è¯¢
2. âŒ æœªä½¿ç”¨CTEï¼ˆå…¬å…±è¡¨è¡¨è¾¾å¼ï¼‰ä¼˜åŒ–å¤æ‚æŸ¥è¯¢
3. âŒ æœªä½¿ç”¨Redisç¼“å­˜ç»“æœ
4. âŒ å®æ—¶è®¡ç®—è€Œéå®šæ—¶æ±‡æ€»

---

### é—®é¢˜2: æ´»è·ƒå®¡æ ¸å‘˜æŸ¥è¯¢ä½¿ç”¨5ä¸ªUNION ğŸ”´ ä¸¥é‡

**ä½ç½®**: `internal/repository/stats_repo.go:203-216`

**é—®é¢˜SQL**:
```sql
SELECT COUNT(DISTINCT reviewer_id) FROM (
    SELECT reviewer_id FROM review_tasks
    WHERE status = 'completed' AND reviewer_id IS NOT NULL

    UNION  -- âš ï¸ UNIONä¼šå»é‡ï¼Œæ¯”UNION ALLæ…¢

    SELECT reviewer_id FROM second_review_tasks
    WHERE status = 'completed' AND reviewer_id IS NOT NULL

    UNION

    SELECT reviewer_id FROM quality_check_tasks
    WHERE status = 'completed' AND reviewer_id IS NOT NULL

    UNION

    SELECT reviewer_id FROM video_first_review_tasks
    WHERE status = 'completed' AND reviewer_id IS NOT NULL

    UNION

    SELECT reviewer_id FROM video_second_review_tasks
    WHERE status = 'completed' AND reviewer_id IS NOT NULL
) AS all_reviewers
```

**æ€§èƒ½å½±å“**:
- **è·¨5å¼ è¡¨æ‰«æ**ï¼Œæ¯å¼ è¡¨5000+è¡Œ
- **UNIONå»é‡**éœ€è¦æ’åºå’Œæ¯”è¾ƒï¼ˆåº”è¯¥ç”¨UNION ALLï¼‰
- æ— æ³•æœ‰æ•ˆä½¿ç”¨ç´¢å¼•
- æŸ¥è¯¢æ—¶é—´éšæ•°æ®é‡çº¿æ€§å¢é•¿

**æ•°æ®é‡å½±å“é¢„ä¼°**:
| ä»»åŠ¡æ•° | æŸ¥è¯¢æ—¶é—´ |
|--------|---------|
| 5,000 | ~50ms |
| 50,000 | ~500ms |
| 100,000 | ~1000ms (1s) |

---

### é—®é¢˜3: æœç´¢åŠŸèƒ½å†…å­˜æ’åºå’Œåˆ†é¡µ ğŸ”´ ä¸¥é‡

**ä½ç½®**: `internal/services/task_service.go:267-352`

**é—®é¢˜ä»£ç **:
```go
func (s *TaskService) SearchTasks(req models.SearchTasksRequest) (*models.SearchTasksResponse, error) {
    var allResults []models.TaskSearchResult

    // é—®é¢˜1: åˆ†åˆ«æŸ¥è¯¢ä¸¤ä¸ªé˜Ÿåˆ—ï¼ˆåº”è¯¥åœ¨æ•°æ®åº“å±‚åˆå¹¶ï¼‰
    if req.QueueType == "first" || req.QueueType == "all" {
        firstResults, firstTotal, err := s.taskRepo.SearchTasks(req)
        allResults = append(allResults, firstResults...)  // âš ï¸ åŠ è½½æ‰€æœ‰ç»“æœåˆ°å†…å­˜
    }

    if req.QueueType == "second" || req.QueueType == "all" {
        secondResults, secondTotal, err := s.secondReviewRepo.SearchSecondReviewTasks(req)
        allResults = append(allResults, secondResults...)  // âš ï¸ åˆåŠ è½½æ‰€æœ‰ç»“æœ
    }

    // é—®é¢˜2: åœ¨å†…å­˜ä¸­æ’åºï¼ˆåº”è¯¥ç”¨æ•°æ®åº“ORDER BYï¼‰
    sort.Slice(allResults, func(i, j int) bool {
        if allResults[i].CompletedAt == nil && allResults[j].CompletedAt == nil {
            return allResults[i].CreatedAt.After(allResults[j].CreatedAt)
        }
        // ... å¤æ‚çš„æ¯”è¾ƒé€»è¾‘
        return allResults[i].CompletedAt.After(*allResults[j].CompletedAt)
    })

    // é—®é¢˜3: åœ¨å†…å­˜ä¸­åˆ†é¡µï¼ˆåº”è¯¥ç”¨æ•°æ®åº“LIMIT/OFFSETï¼‰
    offset := (req.Page - 1) * req.PageSize
    end := offset + req.PageSize
    if end > len(allResults) {
        end = len(allResults)
    }
    allResults = allResults[offset:end]  // âš ï¸ ä¸¢å¼ƒå¤§éƒ¨åˆ†å·²åŠ è½½çš„æ•°æ®

    return &models.SearchTasksResponse{Data: allResults}, nil
}
```

**æ€§èƒ½å½±å“åˆ†æ**:

å‡è®¾æœç´¢æ¡ä»¶åŒ¹é…10,000æ¡è®°å½•ï¼Œç”¨æˆ·åªéœ€è¦ç¬¬1é¡µï¼ˆ10æ¡ï¼‰ï¼š

```
âŒ å½“å‰å®ç°ï¼š
1. æ•°æ®åº“æŸ¥è¯¢ first é˜Ÿåˆ—: åŠ è½½ 5,000 æ¡ â†’ å†…å­˜å ç”¨ ~5MB
2. æ•°æ®åº“æŸ¥è¯¢ second é˜Ÿåˆ—: åŠ è½½ 5,000 æ¡ â†’ å†…å­˜å ç”¨ ~5MB
3. åˆå¹¶æ•°ç»„: 10,000 æ¡ â†’ å†…å­˜å ç”¨ 10MB
4. å†…å­˜æ’åº: 10,000 æ¡æ¯”è¾ƒæ“ä½œ â†’ CPUå¯†é›†
5. å†…å­˜åˆ†é¡µ: åªä¿ç•™ 10 æ¡ï¼Œä¸¢å¼ƒ 9,990 æ¡
6. æ€»å†…å­˜å ç”¨: 10MB
7. æ€»CPUæ—¶é—´: ~200ms

âœ… ä¼˜åŒ–åå®ç°ï¼š
1. æ•°æ®åº“æ‰§è¡Œ UNION ALL + ORDER BY + LIMIT 10
2. åªè¿”å› 10 æ¡è®°å½• â†’ å†…å­˜å ç”¨ ~10KB
3. æ— éœ€å†…å­˜æ’åºå’Œåˆ†é¡µ
4. æ€»å†…å­˜å ç”¨: 10KBï¼ˆå‡å°‘99.9%ï¼‰
5. æ€»æŸ¥è¯¢æ—¶é—´: ~20msï¼ˆå‡å°‘90%ï¼‰
```

**å¯æ‰©å±•æ€§é—®é¢˜**:
- å½“ä»»åŠ¡æ•°è¾¾åˆ°100ä¸‡æ—¶ï¼Œå¯èƒ½åŠ è½½**100MB+æ•°æ®åˆ°å†…å­˜**
- å†…å­˜æ’åºæ—¶é—´å¢é•¿åˆ°**æ•°ç§’**
- å¯èƒ½è§¦å‘Go GCï¼Œå¯¼è‡´STWï¼ˆStop The Worldï¼‰

---

### é—®é¢˜4: è§†é¢‘URLç”Ÿæˆé¢‘ç¹æŸ¥è¯¢æ•°æ®åº“ ğŸŸ¡ ä¸­ç­‰

**ä½ç½®**: `internal/services/video_service.go:109-143`

**é—®é¢˜ä»£ç **:
```go
func (s *VideoService) GenerateVideoURL(videoID int) (*models.GenerateVideoURLResponse, error) {
    // é—®é¢˜: æ¯æ¬¡è¯·æ±‚éƒ½æŸ¥æ•°æ®åº“
    video, err := s.videoRepo.GetVideoByID(videoID)  // âš ï¸ æ•°æ®åº“æŸ¥è¯¢
    if err != nil {
        return nil, fmt.Errorf("video not found: %w", err)
    }

    // æ£€æŸ¥ç¼“å­˜çš„URLæ˜¯å¦è¿‡æœŸ
    if video.VideoURL != nil && video.URLExpiresAt != nil &&
       video.URLExpiresAt.After(time.Now()) {
        return &models.GenerateVideoURLResponse{
            VideoURL:  *video.VideoURL,
            ExpiresAt: *video.URLExpiresAt,
        }, nil
    }

    // ç”Ÿæˆæ–°çš„é¢„ç­¾åURL
    expiration := 1 * time.Hour
    videoURL, err := s.r2Service.GeneratePresignedURL(video.VideoKey, expiration)  // âš ï¸ R2 APIè°ƒç”¨
    if err != nil {
        return nil, err
    }

    // æ›´æ–°æ•°æ®åº“
    s.videoRepo.UpdateVideoURL(videoID, videoURL, expiresAt)  // âš ï¸ åˆä¸€æ¬¡æ•°æ®åº“å†™å…¥

    return response, nil
}
```

**æ€§èƒ½å½±å“**:
- æ¯ä¸ªè§†é¢‘å®¡æ ¸è¯·æ±‚éƒ½è§¦å‘**1æ¬¡æ•°æ®åº“è¯» + å¯èƒ½1æ¬¡æ•°æ®åº“å†™**
- é«˜å¹¶å‘ä¸‹ï¼ˆ50ä¸ªå®¡æ ¸å‘˜åŒæ—¶å·¥ä½œï¼‰ï¼š
  - æ•°æ®åº“QPS: 50 * 2 = 100 QPS
  - R2 APIè°ƒç”¨: å¯èƒ½è§¦å‘é™æµ
- URLåœ¨æ•°æ®åº“ä¸­ç¼“å­˜ï¼Œä½†**æœªä½¿ç”¨Redisç¼“å­˜**

**åœºæ™¯æ¨¡æ‹Ÿ**:
```
å®¡æ ¸å‘˜Aæ‰“å¼€è§†é¢‘1 â†’ æŸ¥DB â†’ ç”ŸæˆURL â†’ å†™DB
å®¡æ ¸å‘˜Bæ‰“å¼€è§†é¢‘1ï¼ˆ5ç§’åï¼‰â†’ æŸ¥DB â†’ è¯»åˆ°ç¼“å­˜URL â†’ è¿”å›
å®¡æ ¸å‘˜Cæ‰“å¼€è§†é¢‘1ï¼ˆ10ç§’åï¼‰â†’ æŸ¥DB â†’ è¯»åˆ°ç¼“å­˜URL â†’ è¿”å›

é—®é¢˜: æ¯æ¬¡éƒ½æŸ¥DBï¼Œå³ä½¿URLåœ¨ç¼“å­˜ä¸­
```

---

### é—®é¢˜5: ç»Ÿè®¡APIæ— Redisç¼“å­˜ ğŸŸ¡ ä¸­ç­‰

**ä½ç½®**: `internal/handlers/admin.go:71-79`

**é—®é¢˜ä»£ç **:
```go
func (h *AdminHandler) GetOverviewStats(c *gin.Context) {
    // é—®é¢˜: ç›´æ¥è°ƒç”¨serviceï¼Œæ— ç¼“å­˜
    stats, err := h.statsService.GetOverviewStats()  // âš ï¸ è§¦å‘10+æ¬¡æ•°æ®åº“æŸ¥è¯¢
    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
        return
    }

    c.JSON(http.StatusOK, stats)
}
```

**é—®é¢˜åˆ†æ**:
- ç®¡ç†å‘˜æ¯æ¬¡åˆ·æ–°é¡µé¢éƒ½è§¦å‘å®Œæ•´ç»Ÿè®¡æŸ¥è¯¢
- ç»Ÿè®¡æ•°æ®å®æ—¶æ€§è¦æ±‚**ä¸é«˜**ï¼ˆ5åˆ†é’Ÿå»¶è¿Ÿå¯æ¥å—ï¼‰
- æœªä½¿ç”¨Redisç¼“å­˜
- æœªä½¿ç”¨ETag/Last-Modifiedç­‰HTTPç¼“å­˜

**ç†æƒ³æµç¨‹**:
```
è¯·æ±‚1: ç®¡ç†å‘˜åˆ·æ–°é¡µé¢
â†’ æ£€æŸ¥Redisç¼“å­˜ (MISS)
â†’ æŸ¥è¯¢æ•°æ®åº“ (10+ æŸ¥è¯¢)
â†’ å†™å…¥Redis (TTL=5åˆ†é’Ÿ)
â†’ è¿”å›ç»“æœ

è¯·æ±‚2-N (5åˆ†é’Ÿå†…): ç®¡ç†å‘˜æˆ–å…¶ä»–ç®¡ç†å‘˜åˆ·æ–°
â†’ æ£€æŸ¥Redisç¼“å­˜ (HIT)
â†’ ç›´æ¥è¿”å›ç¼“å­˜æ•°æ®
â†’ 0æ¬¡æ•°æ®åº“æŸ¥è¯¢
```

---

### é—®é¢˜6: UNION ALLæŸ¥è¯¢è¿‡å¤š ğŸŸ¡ ä¸­ç­‰

**ä½ç½®**: å¤šå¤„ï¼Œä¾‹å¦‚ `stats_repo.go:264-286`

**é—®é¢˜SQL**:
```sql
-- GetHourlyStats å‡½æ•°
SELECT
    EXTRACT(HOUR FROM created_at)::int as hour,
    COUNT(*) as count
FROM (
    SELECT created_at FROM review_results WHERE DATE(created_at) = $1
    UNION ALL
    SELECT created_at FROM second_review_results WHERE DATE(created_at) = $1
    UNION ALL
    SELECT created_at FROM quality_check_results WHERE DATE(created_at) = $1
    UNION ALL
    SELECT created_at FROM video_first_review_results WHERE DATE(created_at) = $1
    UNION ALL
    SELECT created_at FROM video_second_review_results WHERE DATE(created_at) = $1
) all_reviews
GROUP BY hour
ORDER BY hour
```

**é—®é¢˜åˆ†æ**:
- éœ€è¦æ‰«æ**5å¼ è¡¨**
- æ¯å¼ è¡¨éƒ½æ‰§è¡Œ`DATE(created_at) = $1`è¿‡æ»¤
- å¦‚æœæ²¡æœ‰æŒ‰æ—¥æœŸçš„ç´¢å¼•ï¼Œå°†è¿›è¡Œå…¨è¡¨æ‰«æ
- UNION ALLè™½ç„¶æ¯”UNIONå¿«ï¼Œä½†ä»éœ€è¦å¤šæ¬¡è¡¨è®¿é—®

**ç´¢å¼•æ£€æŸ¥**:
```sql
-- å½“å‰ç´¢å¼•ï¼ˆä»åˆ†ææŠ¥å‘Šï¼‰
CREATE INDEX idx_review_results_created_at ON review_results(created_at);

-- é—®é¢˜: DATEå‡½æ•°æ— æ³•ä½¿ç”¨ç´¢å¼•
WHERE DATE(created_at) = '2024-01-01'  -- âŒ æ— æ³•ç”¨ç´¢å¼•

-- ä¼˜åŒ–: ä½¿ç”¨èŒƒå›´æŸ¥è¯¢
WHERE created_at >= '2024-01-01' AND created_at < '2024-01-02'  -- âœ… å¯ç”¨ç´¢å¼•
```

---

### é—®é¢˜7: æ‰¹é‡æäº¤å®¡æ ¸çš„äº‹åŠ¡å¤„ç† ğŸŸ¢ è½»å¾®

**ä½ç½®**: `internal/services/task_service.go:152-160`

**é—®é¢˜ä»£ç **:
```go
func (s *TaskService) SubmitBatchReviews(reviewerID int, reviews []models.SubmitReviewRequest) error {
    for _, review := range reviews {
        if err := s.SubmitReview(reviewerID, review); err != nil {  // âš ï¸ æ¯æ¬¡å•ç‹¬æäº¤
            return err
        }
    }
    return nil
}
```

**é—®é¢˜åˆ†æ**:
- æ¯ä¸ªå®¡æ ¸éƒ½æ˜¯ç‹¬ç«‹çš„äº‹åŠ¡
- å¦‚æœæ‰¹é‡æäº¤20æ¡ï¼Œéœ€è¦**20æ¬¡äº‹åŠ¡æäº¤**
- ç½‘ç»œå¾€è¿”æ¬¡æ•°å¢åŠ 
- æ— æ³•åˆ©ç”¨æ‰¹é‡INSERTä¼˜åŒ–

**ä¼˜åŒ–æ½œåŠ›**:
```go
// âŒ å½“å‰: 20æ¡å®¡æ ¸ = 20æ¬¡æäº¤ = 20æ¬¡ç½‘ç»œå¾€è¿”
for i := 0; i < 20; i++ {
    BEGIN TRANSACTION
    INSERT INTO review_results ...
    COMMIT
}

// âœ… ä¼˜åŒ–: 20æ¡å®¡æ ¸ = 1æ¬¡æäº¤ = 1æ¬¡ç½‘ç»œå¾€è¿”
BEGIN TRANSACTION
INSERT INTO review_results VALUES (...), (...), (...)  -- æ‰¹é‡æ’å…¥
COMMIT
```

---

## ğŸ› ï¸ ä¼˜åŒ–æ–¹æ¡ˆè¯¦è§£

### ä¼˜åŒ–æ–¹æ¡ˆ1: åˆå¹¶ç»Ÿè®¡æŸ¥è¯¢ + Redisç¼“å­˜ ğŸ”´ é«˜ä¼˜å…ˆçº§

**ç›®æ ‡**: å°†GetOverviewStatsä»10+æ¬¡æŸ¥è¯¢å‡å°‘åˆ°1æ¬¡æŸ¥è¯¢ï¼Œå¹¶æ·»åŠ Redisç¼“å­˜

#### å®æ–½æ­¥éª¤

**æ­¥éª¤1: åˆ›å»ºç‰©åŒ–è§†å›¾æˆ–å®šæ—¶æ±‡æ€»è¡¨**

```sql
-- åˆ›å»ºç»Ÿè®¡æ±‡æ€»è¡¨
CREATE TABLE stats_cache (
    id SERIAL PRIMARY KEY,
    cache_key VARCHAR(100) UNIQUE NOT NULL,
    cache_data JSONB NOT NULL,
    updated_at TIMESTAMP DEFAULT NOW()
);

-- åˆ›å»ºç´¢å¼•
CREATE INDEX idx_stats_cache_key ON stats_cache(cache_key);
CREATE INDEX idx_stats_cache_updated ON stats_cache(updated_at);
```

**æ­¥éª¤2: ä¼˜åŒ–GetOverviewStatsæŸ¥è¯¢**

```go
// æ–‡ä»¶: internal/repository/stats_repo.go
func (r *StatsRepository) GetOverviewStats() (*models.StatsOverview, error) {
    stats := &models.StatsOverview{}

    // ä½¿ç”¨å•ä¸ªå¤æ‚æŸ¥è¯¢ä»£æ›¿å¤šæ¬¡æŸ¥è¯¢
    query := `
        WITH comment_first AS (
            SELECT
                COUNT(*) as total,
                COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed,
                COUNT(CASE WHEN status = 'pending' THEN 1 END) as pending,
                COUNT(CASE WHEN status = 'in_progress' THEN 1 END) as in_progress
            FROM review_tasks
        ),
        comment_first_approval AS (
            SELECT
                COUNT(CASE WHEN is_approved = true THEN 1 END) as approved,
                COUNT(CASE WHEN is_approved = false THEN 1 END) as rejected
            FROM review_results
        ),
        comment_second AS (
            SELECT
                COUNT(*) as total,
                COUNT(CASE WHEN status = 'completed' THEN 1 END) as completed,
                COUNT(CASE WHEN status = 'pending' THEN 1 END) as pending,
                COUNT(CASE WHEN status = 'in_progress' THEN 1 END) as in_progress
            FROM second_review_tasks
        ),
        comment_second_approval AS (
            SELECT
                COUNT(CASE WHEN is_approved = true THEN 1 END) as approved,
                COUNT(CASE WHEN is_approved = false THEN 1 END) as rejected
            FROM second_review_results
        ),
        -- ... å…¶ä»–CTEï¼ˆå…¬å…±è¡¨è¡¨è¾¾å¼ï¼‰
        active_reviewers AS (
            SELECT COUNT(DISTINCT reviewer_id) as count
            FROM (
                SELECT reviewer_id FROM review_tasks WHERE status = 'completed'
                UNION ALL  -- æ”¹ç”¨UNION ALLï¼ˆæ— éœ€å»é‡ï¼Œå¤–å±‚å·²ç»DISTINCTï¼‰
                SELECT reviewer_id FROM second_review_tasks WHERE status = 'completed'
                UNION ALL
                SELECT reviewer_id FROM quality_check_tasks WHERE status = 'completed'
                UNION ALL
                SELECT reviewer_id FROM video_first_review_tasks WHERE status = 'completed'
                UNION ALL
                SELECT reviewer_id FROM video_second_review_tasks WHERE status = 'completed'
            ) all_reviewers
            WHERE reviewer_id IS NOT NULL
        )
        SELECT
            -- ä»å„ä¸ªCTEä¸­é€‰æ‹©æ•°æ®
            cf.total, cf.completed, cf.pending, cf.in_progress,
            cfa.approved, cfa.rejected,
            cs.total, cs.completed, cs.pending, cs.in_progress,
            csa.approved, csa.rejected,
            ar.count
        FROM comment_first cf, comment_first_approval cfa,
             comment_second cs, comment_second_approval csa,
             active_reviewers ar
    `

    // å•æ¬¡æŸ¥è¯¢è·å–æ‰€æœ‰æ•°æ®
    err := r.db.QueryRow(query).Scan(
        &stats.CommentReviewStats.FirstReview.TotalTasks,
        &stats.CommentReviewStats.FirstReview.CompletedTasks,
        &stats.CommentReviewStats.FirstReview.PendingTasks,
        &stats.CommentReviewStats.FirstReview.InProgressTasks,
        &stats.CommentReviewStats.FirstReview.ApprovedCount,
        &stats.CommentReviewStats.FirstReview.RejectedCount,
        &stats.CommentReviewStats.SecondReview.TotalTasks,
        &stats.CommentReviewStats.SecondReview.CompletedTasks,
        &stats.CommentReviewStats.SecondReview.PendingTasks,
        &stats.CommentReviewStats.SecondReview.InProgressTasks,
        &stats.CommentReviewStats.SecondReview.ApprovedCount,
        &stats.CommentReviewStats.SecondReview.RejectedCount,
        &stats.ActiveReviewers,
    )

    if err != nil {
        return nil, err
    }

    // è®¡ç®—æ´¾ç”Ÿå­—æ®µ
    if stats.CommentReviewStats.FirstReview.CompletedTasks > 0 {
        stats.CommentReviewStats.FirstReview.ApprovalRate =
            float64(stats.CommentReviewStats.FirstReview.ApprovedCount) /
            float64(stats.CommentReviewStats.FirstReview.CompletedTasks) * 100
    }

    // ... å…¶ä»–è®¡ç®—

    return stats, nil
}
```

**æ­¥éª¤3: åœ¨Serviceå±‚æ·»åŠ Redisç¼“å­˜**

```go
// æ–‡ä»¶: internal/services/stats_service.go
package services

import (
    "comment-review-platform/internal/models"
    "comment-review-platform/internal/repository"
    redispkg "comment-review-platform/pkg/redis"
    "context"
    "encoding/json"
    "time"

    "github.com/redis/go-redis/v9"
)

type StatsService struct {
    statsRepo *repository.StatsRepository
    rdb       *redis.Client
    ctx       context.Context
}

func NewStatsService() *StatsService {
    return &StatsService{
        statsRepo: repository.NewStatsRepository(),
        rdb:       redispkg.Client,
        ctx:       context.Background(),
    }
}

func (s *StatsService) GetOverviewStats() (*models.StatsOverview, error) {
    cacheKey := "stats:overview"
    cacheTTL := 5 * time.Minute  // 5åˆ†é’Ÿç¼“å­˜

    // 1. å°è¯•ä»Redisè¯»å–
    cached, err := s.rdb.Get(s.ctx, cacheKey).Result()
    if err == nil {
        var stats models.StatsOverview
        if err := json.Unmarshal([]byte(cached), &stats); err == nil {
            // ç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥è¿”å›
            return &stats, nil
        }
    }

    // 2. ç¼“å­˜æœªå‘½ä¸­ï¼ŒæŸ¥è¯¢æ•°æ®åº“
    stats, err := s.statsRepo.GetOverviewStats()
    if err != nil {
        return nil, err
    }

    // 3. å†™å…¥Redisç¼“å­˜
    data, err := json.Marshal(stats)
    if err == nil {
        s.rdb.Set(s.ctx, cacheKey, data, cacheTTL)
    }

    return stats, nil
}

// æ·»åŠ å¼ºåˆ¶åˆ·æ–°æ–¹æ³•
func (s *StatsService) RefreshOverviewStats() (*models.StatsOverview, error) {
    cacheKey := "stats:overview"

    // åˆ é™¤ç¼“å­˜
    s.rdb.Del(s.ctx, cacheKey)

    // é‡æ–°æŸ¥è¯¢
    return s.GetOverviewStats()
}
```

**æ­¥éª¤4: åœ¨Handlerå±‚æ·»åŠ åˆ·æ–°æ¥å£**

```go
// æ–‡ä»¶: internal/handlers/admin.go
func (h *AdminHandler) GetOverviewStats(c *gin.Context) {
    // æ£€æŸ¥æ˜¯å¦éœ€è¦å¼ºåˆ¶åˆ·æ–°
    refresh := c.Query("refresh") == "true"

    var stats *models.StatsOverview
    var err error

    if refresh {
        stats, err = h.statsService.RefreshOverviewStats()
    } else {
        stats, err = h.statsService.GetOverviewStats()
    }

    if err != nil {
        c.JSON(http.StatusInternalServerError, gin.H{"error": err.Error()})
        return
    }

    // æ·»åŠ ç¼“å­˜ä¿¡æ¯åˆ°å“åº”å¤´
    c.Header("X-Cache-Status", "HIT")
    c.JSON(http.StatusOK, stats)
}
```

#### é¢„æœŸæ•ˆæœ

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|-------|-------|------|
| æ•°æ®åº“æŸ¥è¯¢æ¬¡æ•° | 10+ | 1 | **90%** |
| å“åº”æ—¶é—´ï¼ˆé¦–æ¬¡ï¼‰ | ~500ms | ~150ms | **70%** |
| å“åº”æ—¶é—´ï¼ˆç¼“å­˜ï¼‰ | ~500ms | ~5ms | **99%** |
| æ•°æ®åº“è´Ÿè½½ | é«˜ | ä½ | **80%** |
| ç¼“å­˜å‘½ä¸­ç‡ | 0% | 95%+ | - |

---

### ä¼˜åŒ–æ–¹æ¡ˆ2: æ•°æ®åº“å±‚æœç´¢æ’åºåˆ†é¡µ ğŸ”´ é«˜ä¼˜å…ˆçº§

**ç›®æ ‡**: å°†æœç´¢åŠŸèƒ½çš„æ’åºå’Œåˆ†é¡µç§»åˆ°æ•°æ®åº“å±‚ï¼Œå‡å°‘å†…å­˜å ç”¨

#### å®æ–½æ­¥éª¤

**æ­¥éª¤1: ä¿®æ”¹Repositoryå±‚ä½¿ç”¨UNIONæŸ¥è¯¢**

```go
// æ–‡ä»¶: internal/repository/task_repo.go
func (r *TaskRepository) SearchTasksUnified(req models.SearchTasksRequest) ([]models.TaskSearchResult, int, error) {
    // æ„å»ºWHEREæ¡ä»¶
    whereClauses := []string{}
    args := []interface{}{}
    argIndex := 1

    // å®¡æ ¸å‘˜ç­›é€‰
    if req.ReviewerID > 0 {
        whereClauses = append(whereClauses, fmt.Sprintf("reviewer_id = $%d", argIndex))
        args = append(args, req.ReviewerID)
        argIndex++
    }

    // çŠ¶æ€ç­›é€‰
    if req.Status != "" {
        whereClauses = append(whereClauses, fmt.Sprintf("status = $%d", argIndex))
        args = append(args, req.Status)
        argIndex++
    }

    // æ—¶é—´èŒƒå›´ç­›é€‰
    if req.StartDate != "" {
        whereClauses = append(whereClauses, fmt.Sprintf("created_at >= $%d", argIndex))
        args = append(args, req.StartDate)
        argIndex++
    }

    if req.EndDate != "" {
        whereClauses = append(whereClauses, fmt.Sprintf("created_at < $%d", argIndex))
        args = append(args, req.EndDate)
        argIndex++
    }

    whereClause := ""
    if len(whereClauses) > 0 {
        whereClause = "WHERE " + strings.Join(whereClauses, " AND ")
    }

    // æ„å»ºUNIONæŸ¥è¯¢ï¼ˆæ ¹æ®QueueTypeï¼‰
    var unionQuery string

    if req.QueueType == "all" || req.QueueType == "first" {
        unionQuery = fmt.Sprintf(`
            SELECT
                rt.id,
                rt.comment_id,
                rt.reviewer_id,
                rt.status,
                rt.created_at,
                rt.claimed_at,
                rt.completed_at,
                'first' as queue_type,
                c.text as comment_text,
                u.username as reviewer_name,
                rr.is_approved,
                rr.tags,
                rr.reason
            FROM review_tasks rt
            INNER JOIN comment c ON rt.comment_id = c.id
            LEFT JOIN users u ON rt.reviewer_id = u.id
            LEFT JOIN review_results rr ON rt.id = rr.task_id
            %s
        `, whereClause)
    }

    if req.QueueType == "all" || req.QueueType == "second" {
        secondQuery := fmt.Sprintf(`
            SELECT
                srt.id,
                srt.comment_id,
                srt.reviewer_id,
                srt.status,
                srt.created_at,
                srt.claimed_at,
                srt.completed_at,
                'second' as queue_type,
                c.text as comment_text,
                u.username as reviewer_name,
                srr.is_approved,
                srr.tags,
                srr.reason
            FROM second_review_tasks srt
            INNER JOIN comment c ON srt.comment_id = c.id
            LEFT JOIN users u ON srt.reviewer_id = u.id
            LEFT JOIN second_review_results srr ON srt.id = srr.second_task_id
            %s
        `, whereClause)

        if unionQuery != "" {
            unionQuery = fmt.Sprintf("(%s) UNION ALL (%s)", unionQuery, secondQuery)
        } else {
            unionQuery = secondQuery
        }
    }

    // æ·»åŠ æ’åºå’Œåˆ†é¡µï¼ˆå…³é”®ä¼˜åŒ–ç‚¹ï¼‰
    offset := (req.Page - 1) * req.PageSize
    finalQuery := fmt.Sprintf(`
        SELECT * FROM (%s) combined_results
        ORDER BY
            CASE WHEN completed_at IS NULL THEN 1 ELSE 0 END,
            COALESCE(completed_at, created_at) DESC
        LIMIT $%d OFFSET $%d
    `, unionQuery, argIndex, argIndex+1)

    args = append(args, req.PageSize, offset)

    // æ‰§è¡ŒæŸ¥è¯¢
    rows, err := r.db.Query(finalQuery, args...)
    if err != nil {
        return nil, 0, err
    }
    defer rows.Close()

    results := []models.TaskSearchResult{}
    for rows.Next() {
        var result models.TaskSearchResult
        var tags []string  // ç”¨äºæ‰«æPostgreSQLæ•°ç»„

        err := rows.Scan(
            &result.ID,
            &result.CommentID,
            &result.ReviewerID,
            &result.Status,
            &result.CreatedAt,
            &result.ClaimedAt,
            &result.CompletedAt,
            &result.QueueType,
            &result.CommentText,
            &result.ReviewerName,
            &result.IsApproved,
            pq.Array(&tags),  // ä½¿ç”¨pq.Arrayæ‰«ææ•°ç»„
            &result.Reason,
        )
        if err != nil {
            return nil, 0, err
        }

        result.Tags = tags
        results = append(results, result)
    }

    // è·å–æ€»æ•°ï¼ˆä½¿ç”¨COUNTæŸ¥è¯¢ï¼‰
    countQuery := fmt.Sprintf(`
        SELECT COUNT(*) FROM (%s) combined_results
    `, unionQuery)

    var totalCount int
    err = r.db.QueryRow(countQuery, args[:len(args)-2]...).Scan(&totalCount)  // å»æ‰LIMITå’ŒOFFSETå‚æ•°
    if err != nil {
        return nil, 0, err
    }

    return results, totalCount, nil
}
```

**æ­¥éª¤2: ç®€åŒ–Serviceå±‚é€»è¾‘**

```go
// æ–‡ä»¶: internal/services/task_service.go
func (s *TaskService) SearchTasks(req models.SearchTasksRequest) (*models.SearchTasksResponse, error) {
    // è®¾ç½®é»˜è®¤å€¼
    if req.Page < 1 {
        req.Page = 1
    }
    if req.PageSize < 1 {
        req.PageSize = 10
    }
    if req.PageSize > 100 {
        req.PageSize = 100
    }
    if req.QueueType == "" {
        req.QueueType = "all"
    }

    // ç›´æ¥è°ƒç”¨ç»Ÿä¸€çš„æœç´¢æ–¹æ³•ï¼ˆæ•°æ®åº“å±‚å·²å®Œæˆæ’åºå’Œåˆ†é¡µï¼‰
    results, totalCount, err := s.taskRepo.SearchTasksUnified(req)
    if err != nil {
        return nil, err
    }

    // è®¡ç®—æ€»é¡µæ•°
    totalPages := totalCount / req.PageSize
    if totalCount%req.PageSize > 0 {
        totalPages++
    }

    response := &models.SearchTasksResponse{
        Data:       results,
        Total:      totalCount,
        Page:       req.Page,
        PageSize:   req.PageSize,
        TotalPages: totalPages,
    }

    return response, nil
}
```

#### é¢„æœŸæ•ˆæœ

| åœºæ™¯ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|-------|-------|------|
| æœç´¢10,000æ¡è®°å½•ï¼Œè¿”å›ç¬¬1é¡µ | åŠ è½½10,000æ¡åˆ°å†…å­˜ | åªåŠ è½½10æ¡ | **å†…å­˜å‡å°‘99.9%** |
| å“åº”æ—¶é—´ | ~500ms | ~50ms | **90%** |
| CPUä½¿ç”¨ç‡ | é«˜ï¼ˆå†…å­˜æ’åºï¼‰ | ä½ | **70%** |
| å¯æ‰©å±•æ€§ | éšæ•°æ®é‡çº¿æ€§å¢é•¿ | æ’å®šæ€§èƒ½ | âœ… |

---

### ä¼˜åŒ–æ–¹æ¡ˆ3: è§†é¢‘URL Redisç¼“å­˜ ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**ç›®æ ‡**: ä½¿ç”¨Redisç¼“å­˜è§†é¢‘é¢„ç­¾åURLï¼Œå‡å°‘æ•°æ®åº“å’ŒR2è®¿é—®

#### å®æ–½æ­¥éª¤

**æ­¥éª¤1: ä¿®æ”¹VideoServiceæ·»åŠ Redisç¼“å­˜**

```go
// æ–‡ä»¶: internal/services/video_service.go
import (
    redispkg "comment-review-platform/pkg/redis"
    "github.com/redis/go-redis/v9"
)

type VideoService struct {
    videoRepo *repository.VideoRepository
    r2Service *r2.R2Service
    rdb       *redis.Client
    ctx       context.Context
}

func NewVideoService() (*VideoService, error) {
    r2Service, err := r2.NewR2Service()
    if err != nil {
        return nil, fmt.Errorf("failed to initialize R2 service: %w", err)
    }

    return &VideoService{
        videoRepo: repository.NewVideoRepository(),
        r2Service: r2Service,
        rdb:       redispkg.Client,
        ctx:       context.Background(),
    }, nil
}

func (s *VideoService) GenerateVideoURL(videoID int) (*models.GenerateVideoURLResponse, error) {
    cacheKey := fmt.Sprintf("video:url:%d", videoID)

    // 1. å…ˆæŸ¥Redisç¼“å­˜
    cached, err := s.rdb.Get(s.ctx, cacheKey).Result()
    if err == nil {
        // ç¼“å­˜å‘½ä¸­ï¼Œè§£æJSON
        var response models.GenerateVideoURLResponse
        if err := json.Unmarshal([]byte(cached), &response); err == nil {
            // æ£€æŸ¥URLæ˜¯å¦è¿‡æœŸï¼ˆç•™5åˆ†é’Ÿç¼“å†²ï¼‰
            if response.ExpiresAt.Add(-5 * time.Minute).After(time.Now()) {
                return &response, nil
            }
        }
    }

    // 2. Redisæœªå‘½ä¸­æˆ–å·²è¿‡æœŸï¼ŒæŸ¥æ•°æ®åº“
    video, err := s.videoRepo.GetVideoByID(videoID)
    if err != nil {
        return nil, fmt.Errorf("video not found: %w", err)
    }

    // 3. æ£€æŸ¥æ•°æ®åº“ä¸­çš„URLæ˜¯å¦æœ‰æ•ˆ
    if video.VideoURL != nil && video.URLExpiresAt != nil &&
       video.URLExpiresAt.Add(-5 * time.Minute).After(time.Now()) {
        response := &models.GenerateVideoURLResponse{
            VideoURL:  *video.VideoURL,
            ExpiresAt: *video.URLExpiresAt,
        }

        // å†™å›Redis
        s.cacheVideoURL(cacheKey, response)

        return response, nil
    }

    // 4. ç”Ÿæˆæ–°çš„é¢„ç­¾åURL
    expiration := 1 * time.Hour
    videoURL, err := s.r2Service.GeneratePresignedURL(video.VideoKey, expiration)
    if err != nil {
        return nil, fmt.Errorf("failed to generate pre-signed URL: %w", err)
    }

    expiresAt := time.Now().Add(expiration)
    response := &models.GenerateVideoURLResponse{
        VideoURL:  videoURL,
        ExpiresAt: expiresAt,
    }

    // 5. å¼‚æ­¥æ›´æ–°æ•°æ®åº“ï¼ˆä¸é˜»å¡å“åº”ï¼‰
    go func() {
        if err := s.videoRepo.UpdateVideoURL(videoID, videoURL, expiresAt); err != nil {
            log.Printf("Warning: Failed to update video URL in database: %v", err)
        }
    }()

    // 6. å†™å…¥Redisç¼“å­˜
    s.cacheVideoURL(cacheKey, response)

    return response, nil
}

// è¾…åŠ©æ–¹æ³•: ç¼“å­˜è§†é¢‘URLåˆ°Redis
func (s *VideoService) cacheVideoURL(cacheKey string, response *models.GenerateVideoURLResponse) {
    data, err := json.Marshal(response)
    if err != nil {
        log.Printf("Warning: Failed to marshal video URL: %v", err)
        return
    }

    // ç¼“å­˜50åˆ†é’Ÿï¼ˆURLæœ‰æ•ˆæœŸ1å°æ—¶ï¼Œç•™10åˆ†é’Ÿç¼“å†²ï¼‰
    ttl := 50 * time.Minute
    if err := s.rdb.Set(s.ctx, cacheKey, data, ttl).Err(); err != nil {
        log.Printf("Warning: Failed to cache video URL to Redis: %v", err)
    }
}
```

#### é¢„æœŸæ•ˆæœ

| æ“ä½œ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡ |
|------|-------|-------|------|
| é¦–æ¬¡è¯·æ±‚è§†é¢‘URL | 1æ¬¡DBè¯» + 1æ¬¡R2è°ƒç”¨ + 1æ¬¡DBå†™ | 1æ¬¡Redisè¯»(MISS) + 1æ¬¡DBè¯» + 1æ¬¡R2è°ƒç”¨ + å¼‚æ­¥DBå†™ + 1æ¬¡Rediså†™ | å“åº”æ—¶é—´-20% |
| åç»­è¯·æ±‚ï¼ˆç¼“å­˜æœŸå†…ï¼‰ | 1æ¬¡DBè¯» | 1æ¬¡Redisè¯»(HIT) | **å“åº”æ—¶é—´-90%** |
| æ•°æ®åº“è´Ÿè½½ | æ¯æ¬¡è¯·æ±‚éƒ½æŸ¥DB | 50åˆ†é’Ÿå†…åªæŸ¥1æ¬¡ | **å‡å°‘98%** |
| R2 APIè°ƒç”¨ | æ¯å°æ—¶å¯èƒ½å¤šæ¬¡ | æ¯å°æ—¶1æ¬¡ | **å‡å°‘95%** |

---

### ä¼˜åŒ–æ–¹æ¡ˆ4: æ·»åŠ æ•°æ®åº“ç´¢å¼•ä¼˜åŒ– ğŸŸ¡ ä¸­ä¼˜å…ˆçº§

**ç›®æ ‡**: æ·»åŠ å¤åˆç´¢å¼•ï¼Œä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½

#### éœ€è¦æ·»åŠ çš„ç´¢å¼•

```sql
-- æ–‡ä»¶: migrations/007_performance_indexes.sql

-- 1. ä»»åŠ¡çŠ¶æ€+é¢†å–æ—¶é—´å¤åˆç´¢å¼•ï¼ˆç”¨äºé‡Šæ”¾è¶…æ—¶ä»»åŠ¡ï¼‰
CREATE INDEX CONCURRENTLY idx_review_tasks_status_claimed
ON review_tasks(status, claimed_at)
WHERE status = 'in_progress';

CREATE INDEX CONCURRENTLY idx_second_review_tasks_status_claimed
ON second_review_tasks(status, claimed_at)
WHERE status = 'in_progress';

CREATE INDEX CONCURRENTLY idx_quality_check_tasks_status_claimed
ON quality_check_tasks(status, claimed_at)
WHERE status = 'in_progress';

CREATE INDEX CONCURRENTLY idx_video_first_review_tasks_status_claimed
ON video_first_review_tasks(status, claimed_at)
WHERE status = 'in_progress';

CREATE INDEX CONCURRENTLY idx_video_second_review_tasks_status_claimed
ON video_second_review_tasks(status, claimed_at)
WHERE status = 'in_progress';

-- 2. å®¡æ ¸å‘˜+çŠ¶æ€å¤åˆç´¢å¼•ï¼ˆç”¨äºæŸ¥è¯¢æˆ‘çš„ä»»åŠ¡ï¼‰
CREATE INDEX CONCURRENTLY idx_review_tasks_reviewer_status
ON review_tasks(reviewer_id, status)
WHERE reviewer_id IS NOT NULL;

CREATE INDEX CONCURRENTLY idx_second_review_tasks_reviewer_status
ON second_review_tasks(reviewer_id, status)
WHERE reviewer_id IS NOT NULL;

-- 3. åˆ›å»ºæ—¶é—´èŒƒå›´æŸ¥è¯¢ç´¢å¼•ï¼ˆç”¨äºç»Ÿè®¡æŸ¥è¯¢ï¼‰
CREATE INDEX CONCURRENTLY idx_review_results_created_date
ON review_results(DATE(created_at), created_at);

CREATE INDEX CONCURRENTLY idx_second_review_results_created_date
ON second_review_results(DATE(created_at), created_at);

CREATE INDEX CONCURRENTLY idx_quality_check_results_created_date
ON quality_check_results(DATE(created_at), created_at);

CREATE INDEX CONCURRENTLY idx_video_first_review_results_created_date
ON video_first_review_results(DATE(created_at), created_at);

CREATE INDEX CONCURRENTLY idx_video_second_review_results_created_date
ON video_second_review_results(DATE(created_at), created_at);

-- 4. å®¡æ ¸å‘˜ç»©æ•ˆç»Ÿè®¡ç´¢å¼•
CREATE INDEX CONCURRENTLY idx_review_results_reviewer_approved
ON review_results(reviewer_id, is_approved);

CREATE INDEX CONCURRENTLY idx_second_review_results_reviewer_approved
ON second_review_results(reviewer_id, is_approved);

-- 5. è§†é¢‘è´¨é‡æ ‡ç­¾ç»Ÿè®¡ç´¢å¼•ï¼ˆGINç´¢å¼•ç”¨äºJSONBï¼‰
CREATE INDEX CONCURRENTLY idx_video_first_review_results_quality_dims
ON video_first_review_results USING GIN (quality_dimensions);

CREATE INDEX CONCURRENTLY idx_video_second_review_results_quality_dims
ON video_second_review_results USING GIN (quality_dimensions);

-- æ³¨æ„: ä½¿ç”¨CONCURRENTLYé¿å…é”è¡¨
```

#### ç´¢å¼•ä½¿ç”¨è¯´æ˜

| ç´¢å¼• | ä½¿ç”¨åœºæ™¯ | é¢„æœŸæå‡ |
|------|---------|---------|
| `idx_*_status_claimed` | é‡Šæ”¾è¶…æ—¶ä»»åŠ¡æŸ¥è¯¢ | **90%** |
| `idx_*_reviewer_status` | æŸ¥è¯¢æˆ‘çš„ä»»åŠ¡ | **80%** |
| `idx_*_created_date` | æ¯æ—¥/æ¯å°æ—¶ç»Ÿè®¡ | **70%** |
| `idx_*_reviewer_approved` | å®¡æ ¸å‘˜ç»©æ•ˆç»Ÿè®¡ | **60%** |
| `idx_*_quality_dims` | è§†é¢‘è´¨é‡æ ‡ç­¾ç»Ÿè®¡ | **50%** |

#### æ³¨æ„äº‹é¡¹

```sql
-- âš ï¸ åˆ›å»ºç´¢å¼•æ³¨æ„äº‹é¡¹:

-- 1. ä½¿ç”¨CONCURRENTLYé¿å…é”è¡¨ï¼ˆç”Ÿäº§ç¯å¢ƒå¿…é¡»ï¼‰
CREATE INDEX CONCURRENTLY ...;

-- 2. ç›‘æ§ç´¢å¼•åˆ›å»ºè¿›åº¦
SELECT
    pid,
    now() - pg_stat_activity.query_start AS duration,
    query
FROM pg_stat_activity
WHERE query LIKE 'CREATE INDEX%';

-- 3. æ£€æŸ¥ç´¢å¼•å¤§å°
SELECT
    schemaname,
    tablename,
    indexname,
    pg_size_pretty(pg_relation_size(indexrelid)) AS index_size
FROM pg_stat_user_indexes
ORDER BY pg_relation_size(indexrelid) DESC;

-- 4. éªŒè¯ç´¢å¼•æ˜¯å¦è¢«ä½¿ç”¨
EXPLAIN ANALYZE
SELECT * FROM review_tasks
WHERE status = 'in_progress'
ORDER BY claimed_at ASC;

-- åº”è¯¥çœ‹åˆ°:
-- Index Scan using idx_review_tasks_status_claimed on review_tasks
```

---

### ä¼˜åŒ–æ–¹æ¡ˆ5: å®šæ—¶ä»»åŠ¡æ±‡æ€»ç»Ÿè®¡æ•°æ® ğŸŸ¢ ä½ä¼˜å…ˆçº§

**ç›®æ ‡**: ä½¿ç”¨åå°ä»»åŠ¡å®šæ—¶æ±‡æ€»ç»Ÿè®¡æ•°æ®ï¼Œé¿å…å®æ—¶è®¡ç®—

#### å®æ–½æ­¥éª¤

**æ­¥éª¤1: åˆ›å»ºç»Ÿè®¡æ±‡æ€»è¡¨**

```sql
-- æ–‡ä»¶: migrations/008_stats_aggregation.sql

CREATE TABLE stats_hourly_agg (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL,
    hour INTEGER NOT NULL,
    queue_type VARCHAR(50) NOT NULL,
    review_count INTEGER DEFAULT 0,
    approved_count INTEGER DEFAULT 0,
    rejected_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(date, hour, queue_type)
);

CREATE TABLE stats_daily_agg (
    id SERIAL PRIMARY KEY,
    date DATE NOT NULL UNIQUE,
    total_reviews INTEGER DEFAULT 0,
    comment_first_reviews INTEGER DEFAULT 0,
    comment_second_reviews INTEGER DEFAULT 0,
    quality_checks INTEGER DEFAULT 0,
    video_first_reviews INTEGER DEFAULT 0,
    video_second_reviews INTEGER DEFAULT 0,
    active_reviewers INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX idx_stats_hourly_date_hour ON stats_hourly_agg(date, hour);
CREATE INDEX idx_stats_daily_date ON stats_daily_agg(date);
```

**æ­¥éª¤2: å®ç°èšåˆå‡½æ•°**

```go
// æ–‡ä»¶: internal/services/stats_aggregation_service.go
package services

import (
    "comment-review-platform/pkg/database"
    "database/sql"
    "log"
    "time"
)

type StatsAggregationService struct {
    db *sql.DB
}

func NewStatsAggregationService() *StatsAggregationService {
    return &StatsAggregationService{
        db: database.DB,
    }
}

// AggregateHourlyStats æ±‡æ€»æ¯å°æ—¶ç»Ÿè®¡æ•°æ®
func (s *StatsAggregationService) AggregateHourlyStats(date time.Time, hour int) error {
    dateStr := date.Format("2006-01-02")

    query := `
        INSERT INTO stats_hourly_agg (date, hour, queue_type, review_count, approved_count, rejected_count, updated_at)
        VALUES
            ($1, $2, 'comment_first',
             (SELECT COUNT(*) FROM review_results WHERE DATE(created_at) = $1 AND EXTRACT(HOUR FROM created_at) = $2),
             (SELECT COUNT(*) FROM review_results WHERE DATE(created_at) = $1 AND EXTRACT(HOUR FROM created_at) = $2 AND is_approved = true),
             (SELECT COUNT(*) FROM review_results WHERE DATE(created_at) = $1 AND EXTRACT(HOUR FROM created_at) = $2 AND is_approved = false),
             NOW()
            ),
            ($1, $2, 'comment_second',
             (SELECT COUNT(*) FROM second_review_results WHERE DATE(created_at) = $1 AND EXTRACT(HOUR FROM created_at) = $2),
             (SELECT COUNT(*) FROM second_review_results WHERE DATE(created_at) = $1 AND EXTRACT(HOUR FROM created_at) = $2 AND is_approved = true),
             (SELECT COUNT(*) FROM second_review_results WHERE DATE(created_at) = $1 AND EXTRACT(HOUR FROM created_at) = $2 AND is_approved = false),
             NOW()
            )
        ON CONFLICT (date, hour, queue_type)
        DO UPDATE SET
            review_count = EXCLUDED.review_count,
            approved_count = EXCLUDED.approved_count,
            rejected_count = EXCLUDED.rejected_count,
            updated_at = NOW()
    `

    _, err := s.db.Exec(query, dateStr, hour)
    if err != nil {
        return err
    }

    log.Printf("Aggregated hourly stats for %s hour %d", dateStr, hour)
    return nil
}

// AggregateDailyStats æ±‡æ€»æ¯æ—¥ç»Ÿè®¡æ•°æ®
func (s *StatsAggregationService) AggregateDailyStats(date time.Time) error {
    dateStr := date.Format("2006-01-02")

    query := `
        INSERT INTO stats_daily_agg (
            date,
            total_reviews,
            comment_first_reviews,
            comment_second_reviews,
            quality_checks,
            video_first_reviews,
            video_second_reviews,
            active_reviewers,
            updated_at
        )
        SELECT
            $1::date,
            (SELECT COUNT(*) FROM review_results WHERE DATE(created_at) = $1) +
            (SELECT COUNT(*) FROM second_review_results WHERE DATE(created_at) = $1) +
            (SELECT COUNT(*) FROM quality_check_results WHERE DATE(created_at) = $1) +
            (SELECT COUNT(*) FROM video_first_review_results WHERE DATE(created_at) = $1) +
            (SELECT COUNT(*) FROM video_second_review_results WHERE DATE(created_at) = $1),
            (SELECT COUNT(*) FROM review_results WHERE DATE(created_at) = $1),
            (SELECT COUNT(*) FROM second_review_results WHERE DATE(created_at) = $1),
            (SELECT COUNT(*) FROM quality_check_results WHERE DATE(created_at) = $1),
            (SELECT COUNT(*) FROM video_first_review_results WHERE DATE(created_at) = $1),
            (SELECT COUNT(*) FROM video_second_review_results WHERE DATE(created_at) = $1),
            (SELECT COUNT(DISTINCT reviewer_id) FROM (
                SELECT reviewer_id FROM review_results WHERE DATE(created_at) = $1
                UNION ALL
                SELECT reviewer_id FROM second_review_results WHERE DATE(created_at) = $1
                UNION ALL
                SELECT reviewer_id FROM quality_check_results WHERE DATE(created_at) = $1
                UNION ALL
                SELECT reviewer_id FROM video_first_review_results WHERE DATE(created_at) = $1
                UNION ALL
                SELECT reviewer_id FROM video_second_review_results WHERE DATE(created_at) = $1
            ) all_reviewers WHERE reviewer_id IS NOT NULL),
            NOW()
        ON CONFLICT (date)
        DO UPDATE SET
            total_reviews = EXCLUDED.total_reviews,
            comment_first_reviews = EXCLUDED.comment_first_reviews,
            comment_second_reviews = EXCLUDED.comment_second_reviews,
            quality_checks = EXCLUDED.quality_checks,
            video_first_reviews = EXCLUDED.video_first_reviews,
            video_second_reviews = EXCLUDED.video_second_reviews,
            active_reviewers = EXCLUDED.active_reviewers,
            updated_at = NOW()
    `

    _, err := s.db.Exec(query, dateStr)
    if err != nil {
        return err
    }

    log.Printf("Aggregated daily stats for %s", dateStr)
    return nil
}
```

**æ­¥éª¤3: åœ¨main.goä¸­å¯åŠ¨å®šæ—¶ä»»åŠ¡**

```go
// æ–‡ä»¶: cmd/api/main.go
func startStatsAggregationWorker() {
    aggService := services.NewStatsAggregationService()

    // æ¯å°æ—¶çš„ç¬¬5åˆ†é’Ÿæ‰§è¡Œèšåˆ
    ticker := time.NewTicker(1 * time.Minute)
    defer ticker.Stop()

    for range ticker.C {
        now := time.Now()

        // æ¯å°æ—¶ç¬¬5åˆ†é’Ÿæ‰§è¡Œ
        if now.Minute() == 5 {
            // æ±‡æ€»ä¸Šä¸€å°æ—¶çš„æ•°æ®
            lastHour := now.Add(-1 * time.Hour)
            if err := aggService.AggregateHourlyStats(lastHour, lastHour.Hour()); err != nil {
                log.Printf("Error aggregating hourly stats: %v", err)
            }
        }

        // æ¯å¤©å‡Œæ™¨1ç‚¹æ‰§è¡Œ
        if now.Hour() == 1 && now.Minute() == 5 {
            // æ±‡æ€»æ˜¨å¤©çš„æ•°æ®
            yesterday := now.AddDate(0, 0, -1)
            if err := aggService.AggregateDailyStats(yesterday); err != nil {
                log.Printf("Error aggregating daily stats: %v", err)
            }
        }
    }
}

func main() {
    // ... å…¶ä»–åˆå§‹åŒ–ä»£ç 

    // å¯åŠ¨åå°ä»»åŠ¡
    go startTaskReleaseWorker()
    go startSamplingScheduler()
    go startStatsAggregationWorker()  // æ–°å¢

    // å¯åŠ¨HTTPæœåŠ¡
    router.Run(":8080")
}
```

#### é¢„æœŸæ•ˆæœ

- ç»Ÿè®¡æŸ¥è¯¢ä»å®æ—¶è®¡ç®—æ”¹ä¸ºæŸ¥è¯¢æ±‡æ€»è¡¨
- å“åº”æ—¶é—´ä»500msé™ä½åˆ°10ms
- å†å²ç»Ÿè®¡æ•°æ®å¯è¿½æº¯

---

## ğŸ“Š å®æ–½ä¼˜å…ˆçº§

### ä¼˜å…ˆçº§çŸ©é˜µ

| ä¼˜åŒ–æ–¹æ¡ˆ | å®æ–½éš¾åº¦ | é¢„æœŸæ”¶ç›Š | ä¼˜å…ˆçº§ | é¢„è®¡å·¥æ—¶ |
|---------|---------|---------|-------|---------|
| æ–¹æ¡ˆ1: åˆå¹¶ç»Ÿè®¡æŸ¥è¯¢+Redisç¼“å­˜ | ä¸­ | æé«˜ | ğŸ”´ P0 | 8å°æ—¶ |
| æ–¹æ¡ˆ2: æ•°æ®åº“å±‚æœç´¢æ’åºåˆ†é¡µ | é«˜ | æé«˜ | ğŸ”´ P0 | 12å°æ—¶ |
| æ–¹æ¡ˆ3: è§†é¢‘URL Redisç¼“å­˜ | ä½ | é«˜ | ğŸŸ¡ P1 | 4å°æ—¶ |
| æ–¹æ¡ˆ4: æ·»åŠ æ•°æ®åº“ç´¢å¼• | ä½ | ä¸­ | ğŸŸ¡ P1 | 2å°æ—¶ |
| æ–¹æ¡ˆ5: å®šæ—¶ä»»åŠ¡æ±‡æ€»ç»Ÿè®¡ | ä¸­ | ä¸­ | ğŸŸ¢ P2 | 10å°æ—¶ |

### å®æ–½è·¯çº¿å›¾

```
ç¬¬ä¸€é˜¶æ®µï¼ˆç«‹å³å®æ–½ï¼‰ï¼š
â”œâ”€â”€ æ–¹æ¡ˆ4: æ·»åŠ æ•°æ®åº“ç´¢å¼•ï¼ˆ2å°æ—¶ï¼‰
â”‚   â””â”€â”€ é£é™©ä½ï¼Œæ”¶ç›Šç«‹ç«¿è§å½±
â””â”€â”€ æ–¹æ¡ˆ1: åˆå¹¶ç»Ÿè®¡æŸ¥è¯¢+Redisç¼“å­˜ï¼ˆ8å°æ—¶ï¼‰
    â””â”€â”€ è§£å†³ç®¡ç†å‘˜åå°æ€§èƒ½é—®é¢˜

ç¬¬äºŒé˜¶æ®µï¼ˆ1å‘¨å†…ï¼‰ï¼š
â”œâ”€â”€ æ–¹æ¡ˆ2: æ•°æ®åº“å±‚æœç´¢æ’åºåˆ†é¡µï¼ˆ12å°æ—¶ï¼‰
â”‚   â””â”€â”€ è§£å†³æœç´¢åŠŸèƒ½å†…å­˜å ç”¨é—®é¢˜
â””â”€â”€ æ–¹æ¡ˆ3: è§†é¢‘URL Redisç¼“å­˜ï¼ˆ4å°æ—¶ï¼‰
    â””â”€â”€ é™ä½æ•°æ®åº“å’ŒR2è´Ÿè½½

ç¬¬ä¸‰é˜¶æ®µï¼ˆ1ä¸ªæœˆå†…ï¼‰ï¼š
â””â”€â”€ æ–¹æ¡ˆ5: å®šæ—¶ä»»åŠ¡æ±‡æ€»ç»Ÿè®¡ï¼ˆ10å°æ—¶ï¼‰
    â””â”€â”€ é•¿æœŸå¯ç»´æŠ¤æ€§ä¼˜åŒ–
```

---

## ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡

### å…³é”®æŒ‡æ ‡å¯¹æ¯”

| æŒ‡æ ‡ | ä¼˜åŒ–å‰ | ä¼˜åŒ–å | æå‡å¹…åº¦ |
|------|-------|-------|---------|
| **ç»Ÿè®¡APIå“åº”æ—¶é—´** | 500ms | 5ms | **99%** â¬‡ï¸ |
| **æœç´¢APIå“åº”æ—¶é—´** | 500ms | 50ms | **90%** â¬‡ï¸ |
| **è§†é¢‘URLç”Ÿæˆæ—¶é—´** | 100ms | 5ms | **95%** â¬‡ï¸ |
| **æ•°æ®åº“QPS** | 200 | 40 | **80%** â¬‡ï¸ |
| **å†…å­˜å ç”¨ï¼ˆæœç´¢ï¼‰** | 10MB | 10KB | **99.9%** â¬‡ï¸ |
| **Redisç¼“å­˜å‘½ä¸­ç‡** | 0% | 95% | +95% â¬†ï¸ |

### å¯æ‰©å±•æ€§æå‡

| æ•°æ®é‡ | ä¼˜åŒ–å‰æœ€å¤§å¹¶å‘ | ä¼˜åŒ–åæœ€å¤§å¹¶å‘ | æå‡ |
|--------|---------------|---------------|------|
| 1ä¸‡ä»»åŠ¡ | 10äºº | 50äºº | **5å€** |
| 10ä¸‡ä»»åŠ¡ | 5äºº | 100äºº | **20å€** |
| 100ä¸‡ä»»åŠ¡ | ä¸å¯ç”¨ | 200äºº | â™¾ï¸ |

---

## âš ï¸ é£é™©è¯„ä¼°

### æŠ€æœ¯é£é™©

| é£é™© | å¯èƒ½æ€§ | å½±å“ | ç¼“è§£æªæ–½ |
|------|-------|------|---------|
| Redisæ•…éšœå¯¼è‡´ç¼“å­˜å¤±æ•ˆ | ä½ | ä¸­ | è®¾ç½®fallbackåˆ°æ•°æ®åº“ï¼Œå¢åŠ ç›‘æ§å‘Šè­¦ |
| å¤æ‚SQLæ€§èƒ½ä¸å¦‚é¢„æœŸ | ä½ | ä¸­ | åœ¨æµ‹è¯•ç¯å¢ƒç”¨ç”Ÿäº§æ•°æ®é‡éªŒè¯EXPLAIN |
| ç´¢å¼•åˆ›å»ºé”è¡¨ | ä¸­ | é«˜ | ä½¿ç”¨CONCURRENTLYï¼Œåœ¨ä½å³°æœŸæ‰§è¡Œ |
| ç»Ÿè®¡æ•°æ®ä¸ä¸€è‡´ | ä½ | ä½ | æä¾›å¼ºåˆ¶åˆ·æ–°æŒ‰é’®ï¼Œè®°å½•åˆ·æ–°æ—¶é—´ |
| å†…å­˜æ³„æ¼ | æä½ | é«˜ | å‹æµ‹éªŒè¯ï¼Œç›‘æ§å†…å­˜ä½¿ç”¨ |

### ä¸šåŠ¡é£é™©

| é£é™© | ç¼“è§£æªæ–½ |
|------|---------|
| ç»Ÿè®¡æ•°æ®å»¶è¿Ÿï¼ˆ5åˆ†é’Ÿï¼‰ | å‘ç”¨æˆ·è¯´æ˜ç¼“å­˜ç­–ç•¥ï¼Œæä¾›åˆ·æ–°æŒ‰é’® |
| å†å²æ•°æ®è¿ç§» | æ— éœ€è¿ç§»ï¼Œä¼˜åŒ–å‘åå…¼å®¹ |
| APIè¡Œä¸ºå˜åŒ– | ä¿æŒAPIæ¥å£ä¸å˜ï¼Œåªä¼˜åŒ–å†…éƒ¨å®ç° |

---

## ğŸ§ª æµ‹è¯•éªŒè¯è®¡åˆ’

### åŠŸèƒ½æµ‹è¯•

```bash
# æµ‹è¯•æ¸…å•
â–¡ ç»Ÿè®¡APIè¿”å›æ•°æ®æ­£ç¡®æ€§
â–¡ æœç´¢åŠŸèƒ½æ’åºæ­£ç¡®æ€§
â–¡ è§†é¢‘URLå¯è®¿é—®æ€§
â–¡ Redisç¼“å­˜å¤±æ•ˆåçš„fallback
â–¡ å¼ºåˆ¶åˆ·æ–°åŠŸèƒ½
```

### æ€§èƒ½æµ‹è¯•

```bash
# ä½¿ç”¨Apache Benchè¿›è¡Œå‹æµ‹
# æµ‹è¯•1: ç»Ÿè®¡API
ab -n 1000 -c 10 http://localhost:8080/api/admin/stats/overview

# æµ‹è¯•2: æœç´¢API
ab -n 1000 -c 10 "http://localhost:8080/api/search/tasks?page=1&page_size=10"

# æµ‹è¯•3: è§†é¢‘URLç”Ÿæˆ
ab -n 500 -c 10 http://localhost:8080/api/admin/videos/generate-url

# é¢„æœŸç»“æœ:
# - å¹³å‡å“åº”æ—¶é—´ < 100ms
# - 99thç™¾åˆ†ä½ < 200ms
# - æ— é”™è¯¯å“åº”
```

### æ•°æ®åº“æ€§èƒ½æµ‹è¯•

```sql
-- éªŒè¯ç´¢å¼•ä½¿ç”¨
EXPLAIN ANALYZE
SELECT * FROM review_tasks
WHERE status = 'in_progress' AND claimed_at < NOW() - INTERVAL '30 minutes';

-- éªŒè¯ç»Ÿè®¡æŸ¥è¯¢æ€§èƒ½
EXPLAIN (ANALYZE, BUFFERS)
SELECT /* å®Œæ•´çš„ç»Ÿè®¡æŸ¥è¯¢ */ ...;

-- é¢„æœŸç»“æœ:
-- - æŸ¥è¯¢æ—¶é—´ < 50ms
-- - ä½¿ç”¨ç´¢å¼•æ‰«æè€Œéå…¨è¡¨æ‰«æ
-- - Bufferså‘½ä¸­ç‡ > 90%
```

### ç›‘æ§æŒ‡æ ‡

```
å®æ–½åéœ€è¦æŒç»­ç›‘æ§:
â–¡ APIå“åº”æ—¶é—´P50/P90/P99
â–¡ æ•°æ®åº“è¿æ¥æ± ä½¿ç”¨ç‡
â–¡ Redisç¼“å­˜å‘½ä¸­ç‡
â–¡ å†…å­˜ä½¿ç”¨é‡
â–¡ CPUä½¿ç”¨ç‡
â–¡ é”™è¯¯ç‡
```

---

## ğŸ“ å®æ–½æ£€æŸ¥æ¸…å•

### ä»£ç ä¿®æ”¹æ¸…å•

```bash
â–¡ ä¿®æ”¹ internal/repository/stats_repo.go - GetOverviewStats()
â–¡ æ–°å»º internal/services/stats_service.go - Redisç¼“å­˜é€»è¾‘
â–¡ ä¿®æ”¹ internal/handlers/admin.go - æ·»åŠ åˆ·æ–°å‚æ•°
â–¡ ä¿®æ”¹ internal/repository/task_repo.go - æ·»åŠ SearchTasksUnified()
â–¡ ä¿®æ”¹ internal/services/task_service.go - ç®€åŒ–SearchTasks()
â–¡ ä¿®æ”¹ internal/services/video_service.go - æ·»åŠ Redisç¼“å­˜
â–¡ æ–°å»º migrations/007_performance_indexes.sql
â–¡ æ–°å»º migrations/008_stats_aggregation.sql
â–¡ æ–°å»º internal/services/stats_aggregation_service.go
â–¡ ä¿®æ”¹ cmd/api/main.go - å¯åŠ¨èšåˆä»»åŠ¡
```

### éƒ¨ç½²æ¸…å•

```bash
â–¡ å¤‡ä»½æ•°æ®åº“
â–¡ åœ¨æµ‹è¯•ç¯å¢ƒéƒ¨ç½²éªŒè¯
â–¡ æ‰§è¡Œæ•°æ®åº“è¿ç§»ï¼ˆåˆ›å»ºç´¢å¼•ï¼‰
â–¡ éƒ¨ç½²æ–°ç‰ˆæœ¬ä»£ç 
â–¡ éªŒè¯åŠŸèƒ½æ­£å¸¸
â–¡ ç›‘æ§æ€§èƒ½æŒ‡æ ‡
â–¡ å‡†å¤‡å›æ»šæ–¹æ¡ˆ
```

### æ–‡æ¡£æ›´æ–°æ¸…å•

```bash
â–¡ æ›´æ–°APIæ–‡æ¡£è¯´æ˜ç¼“å­˜ç­–ç•¥
â–¡ æ›´æ–°è¿ç»´æ–‡æ¡£è¯´æ˜æ–°å¢çš„å®šæ—¶ä»»åŠ¡
â–¡ æ›´æ–°æ•°æ®åº“æ–‡æ¡£è¯´æ˜æ–°å¢çš„ç´¢å¼•å’Œè¡¨
â–¡ ç¼–å†™æ€§èƒ½ä¼˜åŒ–æ€»ç»“æŠ¥å‘Š
```

---

## ğŸ“ å­¦ä¹ èµ„æº

### PostgreSQLæ€§èƒ½ä¼˜åŒ–
- [PostgreSQL EXPLAINè¯¦è§£](https://www.postgresql.org/docs/current/using-explain.html)
- [PostgreSQLç´¢å¼•æœ€ä½³å®è·µ](https://www.postgresql.org/docs/current/indexes.html)
- [SKIP LOCKEDè¯¦è§£](https://www.2ndquadrant.com/en/blog/what-is-select-skip-locked-for-in-postgresql-9-5/)

### Redisç¼“å­˜ç­–ç•¥
- [Redisç¼“å­˜è®¾è®¡æ¨¡å¼](https://redis.io/docs/manual/patterns/)
- [Cache-Asideæ¨¡å¼](https://docs.microsoft.com/en-us/azure/architecture/patterns/cache-aside)

### Goæ€§èƒ½ä¼˜åŒ–
- [Goæ€§èƒ½åˆ†æå·¥å…·pprof](https://golang.org/pkg/net/http/pprof/)
- [Goæ•°æ®åº“è¿æ¥æ± æœ€ä½³å®è·µ](https://go.dev/doc/database/manage-connections)

---

## ğŸ“ æ”¯æŒä¸åé¦ˆ

å¦‚æœ‰ç–‘é—®æˆ–éœ€è¦ååŠ©ï¼Œè¯·ï¼š
- åˆ›å»ºGitHub Issue
- è”ç³»é¡¹ç›®ç»´æŠ¤è€…
- æŸ¥é˜…é¡¹ç›®æ–‡æ¡£: `/doc/README.md`

---

**æ–‡æ¡£ç»“æŸ** | æœ€åæ›´æ–°: 2025-11-24 | ç‰ˆæœ¬: v1.0
